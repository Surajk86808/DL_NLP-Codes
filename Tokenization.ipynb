{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D-SsdWt4LYL",
        "outputId": "8f81ea21-1300-4255-c363-f32182ed8598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f07b4bc7",
        "outputId": "10064277-5e3c-40ef-95d4-615749733371"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"\"\"Hello Welcome to the first's day of learning of nlp\n",
        "where we are going to deep dive in deep leaning after gaianing sufficient\n",
        "knowledge in machine learning\"\"\""
      ],
      "metadata": {
        "id": "oiLDiimt5woX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxJLoZ426NEo",
        "outputId": "c03e457c-dd4a-4ece-e833-bd8614a49375"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Welcome to the first's day of learning of nlp\n",
            "where we are going to deep dive in deep leaning after gaianing sufficient \n",
            "knowledge in machine learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization\n",
        "## Sentence to Paragraphs\n",
        "from nltk.tokenize import sent_tokenize\n",
        "sentences = sent_tokenize(corpus)"
      ],
      "metadata": {
        "id": "K-vqoJoZ6WMK"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in sentences:\n",
        "  print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIbkys397G-v",
        "outputId": "80546d67-cdd0-4cdc-e039-e12f99e9fc5b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello Welcome to the first's day of learning of nlp\n",
            "where we are going to deep dive in deep leaning after gaianing sufficient \n",
            "knowledge in machine learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization where paragrapgh to words\n",
        "# and sentence to word\n",
        "from  nltk.tokenize import word_tokenize\n"
      ],
      "metadata": {
        "id": "2mSUMR0W7cLp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(corpus)\n",
        "# here s(postrophy s) of first's is not printed\n",
        "# for counting that we use wordpunct_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3nKLJWL8LH5",
        "outputId": "fc35112e-8641-400d-8417-562e44ecb52f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'Welcome',\n",
              " 'to',\n",
              " 'the',\n",
              " 'first',\n",
              " \"'s\",\n",
              " 'day',\n",
              " 'of',\n",
              " 'learning',\n",
              " 'of',\n",
              " 'nlp',\n",
              " 'where',\n",
              " 'we',\n",
              " 'are',\n",
              " 'going',\n",
              " 'to',\n",
              " 'deep',\n",
              " 'dive',\n",
              " 'in',\n",
              " 'deep',\n",
              " 'leaning',\n",
              " 'after',\n",
              " 'gaianing',\n",
              " 'sufficient',\n",
              " 'knowledge',\n",
              " 'in',\n",
              " 'machine',\n",
              " 'learning']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(word_tokenize(corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrB00sXZ7w7J",
        "outputId": "0cda9a48-44bf-4cbf-c252-bf51bda4f5fc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sentences to word\n",
        "for sent in sentences:\n",
        "  print(word_tokenize(sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrA18OrW76Ol",
        "outputId": "84a4088c-858c-4b68-f8a8-dfdd5d7fd81e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'Welcome', 'to', 'the', 'first', 'day', 'of', 'learning', 'of', 'nlp', 'where', 'we', 'are', 'going', 'to', 'deep', 'dive', 'in', 'deep', 'leaning', 'after', 'gaianing', 'sufficient', 'knowledge', 'in', 'machine', 'learning']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(word_tokenize(sent))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhrSjHUC8BVM",
        "outputId": "1df66343-9727-4744-9dd3-924a840116a1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize"
      ],
      "metadata": {
        "id": "JxQ484hO8NdG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wordpunct_tokenize(corpus)\n",
        "# here we get s(from first's) as one element in list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jv2_hUS8lQI",
        "outputId": "7fa604ee-8bbe-4c57-e864-c133e475745a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'Welcome',\n",
              " 'to',\n",
              " 'the',\n",
              " 'first',\n",
              " 'day',\n",
              " 'of',\n",
              " 'learning',\n",
              " 'of',\n",
              " 'nlp',\n",
              " 'where',\n",
              " 'we',\n",
              " 'are',\n",
              " 'going',\n",
              " 'to',\n",
              " 'deep',\n",
              " 'dive',\n",
              " 'in',\n",
              " 'deep',\n",
              " 'leaning',\n",
              " 'after',\n",
              " 'gaianing',\n",
              " 'sufficient',\n",
              " 'knowledge',\n",
              " 'in',\n",
              " 'machine',\n",
              " 'learning']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "# here the difference is"
      ],
      "metadata": {
        "id": "tXLi0ZZ_9QK1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = TreebankWordTokenizer()\n",
        "# it does not take arguments"
      ],
      "metadata": {
        "id": "Ka5W-cDL9cSx"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize(corpus)\n",
        "# in all above 2 method full stop was a seperate word but here it is part of that last word\n",
        "# but for last word it"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXF7h35j9jKc",
        "outputId": "e3b66ef4-8f11-4c51-c866-6ae259928f54"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hello',\n",
              " 'Welcome',\n",
              " 'to',\n",
              " 'the',\n",
              " 'first',\n",
              " \"'s\",\n",
              " 'day',\n",
              " 'of',\n",
              " 'learning',\n",
              " 'of',\n",
              " 'nlp',\n",
              " 'where',\n",
              " 'we',\n",
              " 'are',\n",
              " 'going',\n",
              " 'to',\n",
              " 'deep',\n",
              " 'dive',\n",
              " 'in',\n",
              " 'deep',\n",
              " 'leaning',\n",
              " 'after',\n",
              " 'gaianing',\n",
              " 'sufficient',\n",
              " 'knowledge',\n",
              " 'in',\n",
              " 'machine',\n",
              " 'learning']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "LsUcmHBcANLa",
        "outputId": "0ffe4893-2d3f-46b3-8d79-6b745cfc1887"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-35-2830201818.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-35-2830201818.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    git init\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}